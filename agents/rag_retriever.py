# agents/rag_retriever.py
from langchain_chroma import Chroma  # âœ… ìµœì‹  ë²„ì „ import
from langchain_openai import OpenAIEmbeddings
import os

VECTOR_DIR = os.path.join("data", "vectorstore")

def ensure_retriever():
    """Chroma retriever ì´ˆê¸°í™”"""
    embedding = OpenAIEmbeddings(model="text-embedding-3-small")
    retriever = Chroma(
        persist_directory=VECTOR_DIR,
        embedding_function=embedding
    ).as_retriever(search_kwargs={"k": 5})
    return retriever


def retrieve_guidelines(query_terms, feedback: str = None):
    """
    RAG ê²€ìƒ‰ ìˆ˜í–‰
    - query_termsê°€ strì´ë©´ ë‹¨ì¼ ê²€ìƒ‰
    - listë©´ ê° ë¦¬ìŠ¤í¬ í•­ëª©ë³„ ê²€ìƒ‰
    - feedbackì´ ìˆìœ¼ë©´ query í™•ì¥
    """
    retriever = ensure_retriever()
    results = []

    # âœ… ë¦¬ìŠ¤íŠ¸ / ë¬¸ìì—´ ëª¨ë‘ ì²˜ë¦¬
    if isinstance(query_terms, list):
        for term in query_terms:
            query = f"{term} {feedback}" if feedback else term
            print(f"ğŸ” [RAG ê²€ìƒ‰] {query}")
            docs = retriever.get_relevant_documents(query)
            for d in docs[:2]:  # ìƒìœ„ 2ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
                results.append({
                    "risk": term,
                    "content": d.page_content.strip()
                })
    else:
        query = f"{query_terms} {feedback}" if feedback else query_terms
        print(f"ğŸ” [RAG ê²€ìƒ‰] {query}")
        docs = retriever.get_relevant_documents(query)
        for d in docs[:3]:
            results.append({
                "risk": query_terms,
                "content": d.page_content.strip()
            })

    print(f"âœ… ì´ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(results)}")
    return "\n\n".join([r["content"] for r in results])
