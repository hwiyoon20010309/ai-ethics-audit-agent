import os
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

VECTOR_DIR = os.path.join("data", "vectorstore")

def ensure_retriever():
    """Chroma retriever ì´ˆê¸°í™”"""
    embedding = OpenAIEmbeddings(model="text-embedding-3-small")
    retriever = Chroma(
        persist_directory=VECTOR_DIR,
        embedding_function=embedding
    ).as_retriever(search_kwargs={"k": 5})
    return retriever


def retrieve_guidelines(state):
    """state ê¸°ë°˜ ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰"""
    retriever = ensure_retriever()
    results = []
    query_terms = state.get("risk_factors", [])
    feedback = state.get("human_feedback", None)

    print("\nğŸ“š ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ê·¼ê±° ê²€ìƒ‰ ì¤‘...")

    if isinstance(query_terms, list):
        for term in query_terms:
            query = f"{term} {feedback}" if feedback else term
            print(f"ğŸ” [RAG ê²€ìƒ‰] {query}")
            docs = retriever.get_relevant_documents(query)
            for d in docs[:2]:
                results.append({
                    "risk": term,
                    "content": d.page_content.strip()
                })
    else:
        query = f"{query_terms} {feedback}" if feedback else query_terms
        print(f"ğŸ” [RAG ê²€ìƒ‰] {query}")
        docs = retriever.get_relevant_documents(query)
        for d in docs[:3]:
            results.append({
                "risk": query_terms,
                "content": d.page_content.strip()
            })

    print(f"âœ… ì´ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(results)}")

    # âœ… ê²€ìƒ‰ ê²°ê³¼ë¥¼ stateì— ì €ì¥
    state["policy_context"] = "\n\n".join([r["content"] for r in results])
    return state
