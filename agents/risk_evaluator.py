import os
import re
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)


def evaluate_risks(state):
    """
    RAG ë¬¸ë§¥ ê¸°ë°˜ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€
    - ì…ë ¥: state (policy_context, human_feedback)
    - ì¶œë ¥: state["risk_assessment"]
    """
    policy_context = state.get("policy_context", "")
    feedback = state.get("human_feedback", None)

    base_prompt = (
        "ë‹¤ìŒì€ AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ë¬¸ë§¥ì…ë‹ˆë‹¤.\n"
        "ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê° í•­ëª©(ê³µì •ì„±, í¸í–¥ì„±, íˆ¬ëª…ì„±, ì„¤ëª…ê°€ëŠ¥ì„±, í”„ë¼ì´ë²„ì‹œ ë“±)ì— ëŒ€í•´ "
        "1~5ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê°„ë‹¨í•œ ì½”ë©˜íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.\n"
    )

    if feedback:
        base_prompt += f"\nì‚¬ìš©ì í”¼ë“œë°±: {feedback}\n"
        print("ğŸ’¡ ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì¬í‰ê°€ ìˆ˜í–‰ ì¤‘...")

    # === ë¬¸ë§¥ ì²˜ë¦¬ ===
    if isinstance(policy_context, list):
        policy_text = "\n\n".join(
            [getattr(doc, "page_content", str(doc)) for doc in policy_context]
        )
    else:
        policy_text = str(policy_context)

    prompt = f"{base_prompt}\n=== ë¬¸ë§¥ ===\n{policy_text[:4000]}"

    # === LLM í˜¸ì¶œ ===
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4
    )

    result = response.choices[0].message.content

    # âœ… í‰ê°€ ê²°ê³¼ íŒŒì‹±
    state["risk_assessment"] = _parse_evaluation(result)
    print("âœ… ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€ ì™„ë£Œ.")
    return state


def _parse_evaluation(result_text: str):
    """LLM ì¶œë ¥ ê²°ê³¼ë¥¼ dict í˜•íƒœë¡œ íŒŒì‹±"""
    assessment = {}
    lines = result_text.strip().split("\n")

    for line in lines:
        match = re.match(r"(\w+)\s*[:\-]\s*(\d(?:\.\d)?)", line)
        if match:
            key = match.group(1).strip()
            score = float(match.group(2))
            assessment[key] = {"score": score, "comment": line}

    if not assessment:
        assessment["Summary"] = {"score": 0, "comment": result_text}

    return assessment
