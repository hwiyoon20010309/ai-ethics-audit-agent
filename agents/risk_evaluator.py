# agents/risk_evaluator.py
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

def evaluate_risks(policy_context: str, feedback: str = None):
    """
    RAG ë¬¸ë§¥ ê¸°ë°˜ ìœ¤ë¦¬ ë¦¬ìŠ¤í¬ í‰ê°€
    - feedbackì´ ìˆìœ¼ë©´ í‰ê°€ promptì— ë°˜ì˜í•˜ì—¬ ì¬í‰ê°€
    """
    base_prompt = (
        "ë‹¤ìŒì€ AI ìœ¤ë¦¬ ê°€ì´ë“œë¼ì¸ ë¬¸ë§¥ì…ë‹ˆë‹¤.\n"
        "ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê° í•­ëª©(ê³µì •ì„±, í¸í–¥ì„±, íˆ¬ëª…ì„±, ì„¤ëª…ê°€ëŠ¥ì„±, í”„ë¼ì´ë²„ì‹œ ë“±)ì— ëŒ€í•´ "
        "1~5ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ê°„ë‹¨í•œ ì½”ë©˜íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.\n"
    )

    if feedback:
        base_prompt += f"\nì‚¬ìš©ì í”¼ë“œë°±: {feedback}\n"
        print("ğŸ’¡ ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•œ ì¬í‰ê°€ ìˆ˜í–‰ ì¤‘...")

    prompt = f"{base_prompt}\n=== ë¬¸ë§¥ ===\n{policy_context[:4000]}"

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4
    )

    result = response.choices[0].message.content
    return parse_evaluation(result)

def parse_evaluation(result_text: str):
    """
    ë‹¨ìˆœ í…ìŠ¤íŠ¸ íŒŒì„œ: LLM ì¶œë ¥ â†’ dict ë³€í™˜
    """
    import re
    assessment = {}
    lines = result_text.strip().split("\n")
    for line in lines:
        match = re.match(r"(\w+)\s*[:\-]\s*(\d(?:\.\d)?)", line)
        if match:
            key = match.group(1).strip()
            score = float(match.group(2))
            assessment[key] = {"score": score, "comment": line}
    if not assessment:
        assessment["Summary"] = {"score": 0, "comment": result_text}
    return assessment
